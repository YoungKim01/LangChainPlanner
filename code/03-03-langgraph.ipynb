{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code - https://python.langchain.com/docs/langgraph\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_key = os.environ[\"AZURE_OPENAI_KEY\"]\n",
    "search_endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "search_key = os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import END, MessageGraph\n",
    "\n",
    "# model = ChatOpenAI(temperature=0)\n",
    "\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt-4\",\n",
    "    api_key=azure_openai_key,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_version=\"2023-09-01-preview\",    \n",
    ")\n",
    "\n",
    "\n",
    "graph = MessageGraph()\n",
    "\n",
    "graph.add_node(\"oracle\", model) #node: calls the model with the given input   #The chat model returns an AIMessage. LangGraph adds this to the state.\n",
    "graph.add_edge(\"oracle\", END)   # ((oracle)) --edge-- ((END))\n",
    "\n",
    "graph.set_entry_point(\"oracle\") # oracle node is entry point\n",
    "\n",
    "runnable = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 1 + 1?', id='f8ddd2a4-da25-442b-bdbb-ea5876e52615'),\n",
       " AIMessage(content='2', response_metadata={'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='d0903404-3a22-475c-bd63-eef88c8cd2ee')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke(HumanMessage(\"What is 1 + 1?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional edges\n",
    "\n",
    "Now, let's move onto something a little bit less trivial. Because math can be difficult for LLMs, let's allow the LLM to conditionally call a \"multiply\" node using tool calling.\n",
    "\n",
    "We'll recreate our graph with an additional \"multiply\" that will take the result of the most recent message, if it is a tool call, and calculate the result. We'll also bind the calculator to the OpenAI model as a tool to allow the model to optionally use the tool necessary to respond to the current state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "from typing import List\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(first_number: int, second_number: int):\n",
    "    \"\"\"Multiplies two numbers together.\"\"\"\n",
    "    return first_number * second_number\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_with_tools = model.bind(tools=[convert_to_openai_tool(multiply)])\n",
    "\n",
    "graph = MessageGraph()\n",
    "\n",
    "def invoke_model(state: List[BaseMessage]):\n",
    "    return model_with_tools.invoke(state)\n",
    "\n",
    "graph.add_node(\"oracle\", invoke_model)\n",
    "\n",
    "def invoke_tool(state: List[BaseMessage]):\n",
    "    tool_calls = state[-1].additional_kwargs.get(\"tool_calls\", [])\n",
    "    multiply_call = None\n",
    "\n",
    "    for tool_call in tool_calls:\n",
    "        if tool_call.get(\"function\").get(\"name\") == \"multiply\":\n",
    "            multiply_call = tool_call\n",
    "\n",
    "    if multiply_call is None:\n",
    "        raise Exception(\"No adder input found.\")\n",
    "\n",
    "    res = multiply.invoke(\n",
    "        json.loads(multiply_call.get(\"function\").get(\"arguments\"))\n",
    "    )\n",
    "\n",
    "    return ToolMessage(\n",
    "        tool_call_id=multiply_call.get(\"id\"),\n",
    "        content=res\n",
    "    )\n",
    "\n",
    "graph.add_node(\"multiply\", invoke_tool)\n",
    "\n",
    "graph.add_edge(\"multiply\", END)\n",
    "\n",
    "graph.set_entry_point(\"oracle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: List[BaseMessage]):\n",
    "    tool_calls = state[-1].additional_kwargs.get(\"tool_calls\", [])\n",
    "    if len(tool_calls):\n",
    "        return \"multiply\"\n",
    "    else:\n",
    "        return \"end\"\n",
    "\n",
    "graph.add_conditional_edges(\"oracle\", router, {\n",
    "    \"multiply\": \"multiply\",\n",
    "    \"end\": END,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 123 * 456?', id='47480786-d330-4843-aab0-a0cfb0026251'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_wzkcQtzyfmS3exSXrCKyfPAW', 'function': {'arguments': '{\\n  \"first_number\": 123,\\n  \"second_number\": 456\\n}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='1129443e-da83-402f-8447-08d6309dbf99'),\n",
       " ToolMessage(content='56088', id='69f2dba1-9537-4f6f-8203-ecaf713fb361', tool_call_id='call_wzkcQtzyfmS3exSXrCKyfPAW')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable = graph.compile()\n",
    "\n",
    "runnable.invoke(HumanMessage(\"What is 123 * 456?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
